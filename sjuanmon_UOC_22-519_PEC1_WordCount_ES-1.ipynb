{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU_AzGIgUAvv"
   },
   "source": [
    "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png)  ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
    "\n",
    "# PEC M5: Procesamiento de datos con Apache Spark mediante RDDs (4 Dic 2024 - 31 Dic 2024)\n",
    "\n",
    "# Contando palabras: Construye una aplicación que cuente palabras\n",
    "\n",
    "En este laboratorio se trabajarán las tecnologías descritas en los materiales del curso sobre Spark para desarrollar una aplicación de conteo de palabras. \n",
    "\n",
    "Con el uso masivo de Internet y las redes sociales, el volumen de texto no estructurado está creciendo dramáticamente, y Spark es una gran herramienta para analizar este tipo de datos. En esta PEC, vamos a escribir código para encontrar las palabras más comunes en un archivo de texto con contenido de la biblia en inglés [Corpus Canterbury](https://corpus.canterbury.ac.nz/descriptions/).\n",
    "\n",
    "\n",
    "Lo más interesante de la forma de trabajar en esta práctica es que podría escalarse para, por ejemplo, encontrar las palabras más comunes en Wikipedia.\n",
    "\n",
    "## Durante esta PEC vamos a cubrir:\n",
    "\n",
    "* *Parte 1:* Creación de un RDD y un pair RDD - **1.5 PUNTOS**\n",
    "* *Parte 2:* Contar palabras usando un pair RDD - **2.5 PUNTOS**\n",
    "* *Parte 3:* Encontrar las palabras individuales y su frecuencia de aparición media - **1 PUNTO**\n",
    "* *Parte 4:* Aplicar las funcionalidades desarrolladas a un archivo de texto - **2 PUNTOS**\n",
    "* *Parte 5:* Calcular algunos estadísticos - **3 PUNTOS**\n",
    "\n",
    "\n",
    "> Como referencia a todos los detalles de los métodos que se usan en esta práctica usar:\n",
    "> * [API Python de Spark](https://spark.apache.org/docs/2.4.0/api/python/pyspark.html#pyspark.RDD)\n",
    "\n",
    "## Formato de entrega:\n",
    "\n",
    "Para realizar la entrega, debéis subir los dos notebooks al apartado de evaluación, con el siguiente nombre:\n",
    "\n",
    "* usuarioUOC_22.519_PEC1_WordCount_ES.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOlGjKpGUAvy"
   },
   "source": [
    "## Parte 1: Creacion de un RDD y un pair RDDs\n",
    "\n",
    "En esta sección, exploraremos como crear RRDs usando `parallelize` y como aplicar pair RDDs al problema del conteo de palabras.\n",
    "\n",
    "### (0) Configuración del entorno python + spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F8iqGOuBUAvy"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "sc = pyspark.SparkContext(master=\"local[1]\", appName=\"PAC1_sjuanmon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ir5gsMAUAvz"
   },
   "source": [
    "### (1a) Creación de un RDD\n",
    "Empecemos generando un RDD a partir de una lista de Python y el método `sc.parallelize`. Luego mostraremos por pantalla el tipo de la variable generada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "b9kkxkNeUAvz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat']\n",
    "wordsRDD = sc.parallelize(wordsList, 4)\n",
    "# Print out the type of wordsRDD\n",
    "type(wordsRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNoKG_7-UAvz"
   },
   "source": [
    "### (1b) Crear el plural de las palabras y testear\n",
    "\n",
    "Vamos a utilizar una transformación `map()` para incorporar la letra 's' a cada uno de los strings almacenados en el RDD que acabamos de crear. Vamos a definir una función de Python que devuelva una palabra, que se le ha pasado como parámetro, incorporando una \"s\" al final de la misma. Reemplazar el texto `<FILL IN>` con la solución propuesta. después de haber definido correctamente la función `makePlural`, ejecutar la segunda celda que contiene un assert de test. Si la solución es correcta, se imprimira `1 test passed`.\n",
    "\n",
    "Esta será la forma habitual de trabajar en las PECs. Los ejercicios contendrán una explicación de lo que se espera, seguido de una celda de Código con uno o más `<FILL IN>`. Las celdas que necesiten ser modificadas contendrán el texto `# TODO: Replace <FILL IN> with appropriate code` en la primera línea.\n",
    "\n",
    "Una vez se hayan sustituido todos los `<FILL IN>` por el Código Python adecuado, ejecutar la celda, y posteriormente ejecutar la celda siguiente de test para comprobar que la solución es la esperada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Kr-4bemUUAvz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cats'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def makePlural(word):\n",
    "    \"\"\"Adds an 's' to `word`.\n",
    "\n",
    "    Note:\n",
    "        This is a simple function that only adds an 's'.  \n",
    "\n",
    "    Args:\n",
    "        word (str): A string.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with 's' added to it.\n",
    "    \"\"\"\n",
    "    #return <FILL IN>\n",
    "    return word + 's' \n",
    "\n",
    "makePlural('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DBqFmkj-UAv0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test correcto\n"
     ]
    }
   ],
   "source": [
    "# TEST Pluralize and test (1b)\n",
    "assert makePlural('rat') == 'rats', 'incorrect result: makePlural does not add an s'\n",
    "print (\"1 test passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JggznEUpUAv0"
   },
   "source": [
    "### (1c) Aplicar `makePlural` a nuestro RDD\n",
    "\n",
    "Ahora es el momento de aplicar nuestra función `makePlural()` a todos los elementos del RDD usando una transformación [map()](https://spark.apache.org/docs/2.4.0/api/python/pyspark.html#pyspark.RDD.map). Posteriormente ejecutar la acción [collect()](http://spark.apache.org/docs/2.4.0/api/python/pyspark.html#pyspark.RDD.collect) para obtener el RDD transformado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AvO0iQcCUAv0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats', 'elephants', 'rats', 'rats', 'cats']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "pluralRDD = wordsRDD.map(makePlural)\n",
    "pluralRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oXbLJ4JXUAv0"
   },
   "outputs": [],
   "source": [
    "# TEST Apply makePlural to the base RDD(1c)\n",
    "assert pluralRDD.collect() == ['cats', 'elephants', 'rats', 'rats', 'cats'], 'incorrect values for pluralRDD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stnxOD-RUAv0"
   },
   "source": [
    "### (1d) Ejecutar una funcion `lambda` en un `map`\n",
    "\n",
    "Vamos a crear el mismo RDD usando una `lambda` function en lugar de una función con nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "w3RdGvskUAv0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats', 'elephants', 'rats', 'rats', 'cats']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "pluralLambdaRDD = wordsRDD.map(lambda word: word + 's')\n",
    "print(pluralLambdaRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Tg_TyFp4UAv1"
   },
   "outputs": [],
   "source": [
    "# TEST Pass a lambda function to map (1d)\n",
    "assert pluralLambdaRDD.collect() == ['cats', 'elephants', 'rats', 'rats', 'cats'], 'incorrect values for pluralLambdaRDD (1d)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4duNGhDUAv1"
   },
   "source": [
    "### (1e) Numero de caracteres de cada una de las palabras\n",
    "\n",
    "Ahora vamos a usar un `map()` y una función lambda `lambda` para obtener el número de caracteres de cada palabra. Usaremos `collect` para guardar este resultado directamente en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "79i88VmBUAv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "pluralLengths = (pluralRDD.map(lambda word: len(word)).collect())\n",
    "print(pluralLengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AUfvQl6hUAv1"
   },
   "outputs": [],
   "source": [
    "# TEST Length of each word (1e)\n",
    "assert pluralLengths == [4, 9, 4, 4, 4], 'incorrect values for pluralLengths'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nygi0_YgUAv1"
   },
   "source": [
    "### (1f) Pair RDDs\n",
    "\n",
    "El siguiente paso para completar nuestro programa de conteo de palabras en crear un nuevo tipo de RDD, llamado pair RDD. Un pair RDD es un RDD donde cada elemento es un tupla del estilo `(k, v)` donde `k` es la clave y `v` es su valor correspondiente. En este ejemplo, crearemos una pair RDD consistente en tuplas con el formato `('<word>', 1)` para cada elemento de nuestro RDD básico.\n",
    "\n",
    "Podemos crear nuestro pair RDD usando una transformación `map()` con una `lambda()` function que cree un nuevo RDD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tfdCajY2UAv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 1), ('elephant', 1), ('rat', 1), ('rat', 1), ('cat', 1)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "wordPairs = wordsRDD.map(lambda word: (word, 1))\n",
    "print(wordPairs.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wS8XcRTnUAv1"
   },
   "outputs": [],
   "source": [
    "# TEST Pair RDDs (1f)\n",
    "assert wordPairs.collect() == [('cat', 1), ('elephant', 1), ('rat', 1), ('rat', 1), ('cat', 1)], 'incorrect value for wordPairs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0LQd9pOUAv1"
   },
   "source": [
    "## Parte 2: Contar palabras usando un pair RDD\n",
    "\n",
    "Ahora, contaremos el número de veces que una palabra en particular aparece en el RDD. Esta operación se puede realizar de una infinidad de maneras, pero algunas serán mucho menos eficientes que otras.\n",
    "\n",
    "Un solución muy sencilla seria usar `collect()` sobre todos los elementos devolverlos al driver y allí contarlos. Mientras esta forma de trabajar podría funcionar con textos relativamente cortos, nosotros lo que queremos es poder trabajar con textos de cualquier longitud. Adicionalmente, ejecutar todo el cálculo en el driver es mucho más lento que ejecutarlo en paralelo en los workers. Por estos motivos, en esta práctica usaremos operaciones paralelizables.\n",
    "\n",
    "\n",
    "### (2a) Usando `groupByKey()`\n",
    "Una primera solución a nuestro problema, luego veremos que hay otras mucho más eficientes, se podría basar en la transformación [groupByKey()](http://spark.apache.org/docs/2.4.0/api/python/pyspark.html#pyspark.RDD.groupByKey). Como su nombre indica, la transformación `groupByKey()` agrupa todos los elementos de un RDD que compartan la misma clave en una única lista dentro de una de las particiones.\n",
    "\n",
    "Esta operación plantea dos problemas:\n",
    "  + Esta operación necesita mover todos los valores dentro de la partición adecuada. Esto satura la red. \n",
    "  + Las listas generadas pueden llegar a ser muy grandes llegando incluso a saturar la memoria de alguno de los trabajadores\n",
    "  \n",
    "Utiliza `groupByKey()` para generar un pair RDD del tipo `('word', iterator)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0RWmdQFLUAv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: [1, 1]\n",
      "elephant: [1]\n",
      "rat: [1, 1]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# Note that groupByKey requires no parameters\n",
    "wordsGrouped = wordPairs.groupByKey()\n",
    "for key, value in wordsGrouped.collect():\n",
    "    print('{0}: {1}'.format(key, list(value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Rs1VITEcUAv2"
   },
   "outputs": [],
   "source": [
    "# TEST groupByKey() approach (2a)\n",
    "assert sorted(wordsGrouped.mapValues(lambda x: list(x)).collect()) == [('cat', [1, 1]), ('elephant', [1]), ('rat', [1, 1])], 'incorrect value for wordsGrouped'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ao3HOCnUAv2"
   },
   "source": [
    "### (2b) Utiliza `groupByKey()` para obtener los conteos\n",
    "\n",
    "Usando la transformación `groupByKey()` crea un RDD que contenga 2 elementos, donde cada uno de ellos sea un par palabra (clave) iterador de Python (valor).\n",
    "\n",
    "Luego suma todos los valores de iterador usando una transformación `map()`. El resultado debe ser un pair RDD que contenga las parejas (word, count).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Wl9NDpfaUAv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "wordCountsGrouped = wordsGrouped.map(lambda x: (x[0], sum(x[1])))\n",
    "print(wordCountsGrouped.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Y-gYf8eDUAv2"
   },
   "outputs": [],
   "source": [
    "# TEST Use groupByKey() to obtain the counts (2b)\n",
    "assert sorted(wordCountsGrouped.collect())==[('cat', 2), ('elephant', 1), ('rat', 2)],'incorrect value for wordCountsGrouped'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R6uGj_XUAv2"
   },
   "source": [
    "### (2c) Conteo usando `reduceByKey`\n",
    "\n",
    "Una mejor solución es comenzar desde un pair RDD y luego usar la transformación [reduceByKey()](http://spark.apache.org/docs/2.4.0/api/python/pyspark.html#pyspark.RDD.reduceByKey) para crear un nuevo pair RDD. La transformación `reduceByKey()` agrupa todas las parejas que comparten la misma clave. Posteriormente aplica la funcion que se le pasa por parámetro agrupando los valores de dos en dos. Este proceso se repite iterativamente hasta que obtenemos un único valor agregado para cada una de las claves del pair RDD. `reduceByKey()` opera aplicando la función primero dentro de cada una de las particiones de forma independiente, y posteriormente únicamente comparte los valores agregados entre particiones diferentes, permitiéndole escalar de forma eficiente ya que no tiene necesidad de desplazar por la red una gran cantidad de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IagY-OxbUAv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# Note that reduceByKey takes in a function that accepts two values and returns a single value\n",
    "wordCounts = wordPairs.reduceByKey((lambda a, b: a + b))\n",
    "print (wordCounts.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8OC9pZ3VUAv2"
   },
   "outputs": [],
   "source": [
    "# TEST Counting using reduceByKey (2c)\n",
    "assert sorted(wordCounts.collect())==[('cat', 2), ('elephant', 1), ('rat', 2)],'incorrect value for wordCounts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bul8z1FxUAv3"
   },
   "source": [
    "### (2d) Ahora todo junto\n",
    "\n",
    "La versión más compleja del Código ejecuta primero un `map()` sobre el pair RDD, la transformación `reduceByKey()`, y finalmente la acción `collect()` en una única línea de Código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NZus2tT1UAv3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "wordCountsCollected = (wordsRDD\n",
    "                       .map(lambda word: (word, 1))\n",
    "                       .reduceByKey(lambda a, b: a + b)\n",
    "                       .collect())\n",
    "print(wordCountsCollected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "QJIImGKDUAv3"
   },
   "outputs": [],
   "source": [
    "# TEST All together (2d)\n",
    "assert sorted(wordCountsCollected)==[('cat', 2), ('elephant', 1), ('rat', 2)],'incorrect value for wordCountsCollected'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y51nNytZUAv3"
   },
   "source": [
    "## Parte 3: Encontrar las palabras individuales y su frecuencia de aparición media\n",
    "\n",
    "### (3a) Palabras únicas\n",
    "\n",
    "Calcular el número de palabras únicas en `wordsRDD`. Puedes utilizar otros RDDs que hayas creado en esta práctica si te resulta más sencillo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "AZOfny2PUAv3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "uniqueWords = wordsRDD.distinct().count()\n",
    "print(uniqueWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "EqAQ8HQ-UAv3"
   },
   "outputs": [],
   "source": [
    "# TEST Unique words (3a)\n",
    "assert uniqueWords== 3, 'incorrect count of uniqueWords'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zLHxu4VUAv3"
   },
   "source": [
    "### (3b) Calcular la media usando `reduce()`\n",
    "\n",
    "Encuentra la frecuencia media de aparición de palabras en `wordCounts`.\n",
    "\n",
    "Utiliza la acción `reduce()` para sumar los conteos en `wordCounts` y entonces divide por el número de palabras únicas. Para realizar esto primero aplica un `map()` al pair RDD `wordCounts`, que está formado por tuplas con el formato (key, value), para convertirlo en un RDD de valores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "USu_rtacUAv3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1.67\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "from operator import add\n",
    "totalCount = (wordCounts\n",
    "              .map((lambda x: x[1]))\n",
    "              .reduce(add))\n",
    "average = totalCount / float(len(wordCounts.collect()))\n",
    "print(totalCount)\n",
    "print(round(average, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3lEUGjUzUAv3"
   },
   "outputs": [],
   "source": [
    "# TEST Mean using reduce (3b)\n",
    "assert round(average, 2)==1.67, 'incorrect value of average'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkXpIsAXUAv4"
   },
   "source": [
    "## Parte 4: Aplicar las funcionalidades desarrolladas a un archivo de texto\n",
    "\n",
    "Para esto hemos de construir una función `wordCount`, capaz de trabajar con datos del mundo real que suelen presentan problemas como el uso de mayúsculas o minúsculas, puntuación, acentos, etc. Posteriormente, cargar los datos de nuestra fuente de datos y finalmente, calcular el conteo de palabras sobre los datos procesados.\n",
    "\n",
    "### (4a) función `wordCount`\n",
    "\n",
    "Primero, define una función para el conteo de palabras. deberías reutilizar las técnicas que has visto en los apartados anteriores de esta práctica. Dicha función, ha de tomar un RDD que contenga una lista de palabras, y devolver un pair RDD que contenga todas las palabras con sus correspondientes conteos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Soh4Co_BUAv4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def wordCount(wordListRDD):\n",
    "    \"\"\"Creates a pair RDD with word counts from an RDD of words.\n",
    "\n",
    "    Args:\n",
    "        wordListRDD (RDD of str): An RDD consisting of words.\n",
    "\n",
    "    Returns:\n",
    "        RDD of (str, int): An RDD consisting of (word, count) tuples.\n",
    "    \"\"\"\n",
    "    return wordListRDD \\\n",
    "        .map(lambda word: (word, 1)) \\\n",
    "        .reduceByKey(lambda a, b: a + b)\n",
    "print(wordCount(wordsRDD).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "SkG-Ni6jUAv4"
   },
   "outputs": [],
   "source": [
    "# TEST wordCount function (4a)\n",
    "assert sorted(wordCount(wordsRDD).collect())==[('cat', 2), ('elephant', 1), ('rat', 2)],'incorrect definition for wordCount function'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPyU-FY2UAv4"
   },
   "source": [
    "### (4b) Mayúsculas y puntuación\n",
    "\n",
    "Los ficheros del mundo real son mucho más complejos que los que hemos estado usando en esta PEC. Algunos de los problemas que son necesarios de solucionar son:\n",
    "  + Las palabras deben de contarse independientemente de si están en mayúscula o minúscula (por ejemplo, Spark y spark deberían contarse como la misma palabra).\n",
    "  + Todos los signos de puntuación han de eliminarse.\n",
    "  + Cualquier espacio al principio o al final de la palabra ha de eliminarse.\n",
    "  \n",
    "Define la función `removePunctuation` que convierta todo el texto a minúsculas, elimine los signos de puntuación, y elimine los espacios al principio y fin de cada palabra. Usa el módulo de Python [re](https://docs.python.org/2/library/re.html) para eliminar cualquier carácter que no sea una letra, un numero o un espacio.\n",
    "\n",
    "Sino estas familiarizado con las expresiones regulares deberías revisar [este tutorial](https://developers.google.com/edu/python/regular-expressions). Alternativamente, [esta web](https://regex101.com/#python) es de gran ayuda para debugar tus expresiones regulares.\n",
    "\n",
    "**Hints**\n",
    "\n",
    "1. Usa la función [re.sub()](https://docs.python.org/2.7/library/re.html#re.sub).\n",
    "2. Para nuestros propósitos, \"puntuación\" significa \"no alfabético, numérico, o espacio.\" La expresión regular que define estos caracteres es: `[^A-Za-z\\s\\d]`\n",
    "3. No usar `\\W`, ya que retendrá los guiones bajos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "W1CTTYCjUAv4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi you\n",
      "no underscore\n",
      "remove punctuation then spaces\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "import re\n",
    "def removePunctuation(text):\n",
    "    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\n",
    "\n",
    "    Note:\n",
    "        Only whitespace, letters, and numbers should be retained.  Other characters should should be\n",
    "        eliminated (e.g. it's becomes its).  Leading and trailing spaces should be removed after\n",
    "        punctuation is removed.\n",
    "\n",
    "    Args:\n",
    "        text (str): A string.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned up string.\n",
    "    \"\"\"\n",
    "    # Eliminar caracteres no alfabéticos, numéricos ni espacios\n",
    "    cleaned_text = re.sub(r'[^A-Za-z\\s\\d]', '', text)\n",
    "    \n",
    "    # Convertir a minúsculas y eliminar espacios al principio y al final\n",
    "    cleaned_text = cleaned_text.lower().strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "    \n",
    "print(removePunctuation('Hi, you!'))\n",
    "print(removePunctuation(' No under_score!'))\n",
    "print(removePunctuation(' *      Remove punctuation then spaces  * '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "gBUH5cXDUAv4"
   },
   "outputs": [],
   "source": [
    "# TEST Capitalization and punctuation (4b)\n",
    "assert removePunctuation(\" The Elephant's 4 cats. \") == 'the elephants 4 cats', 'incorrect definition for removePunctuation function'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2uFF4D7UAv4"
   },
   "source": [
    "### (4c) Cargar un archivo de texto\n",
    "\n",
    "Para la siguiente parte, usaremos el fichero de la biblia en inglés ya mencionada. \n",
    "Para convertir un archivo de texto en un RDD, usaremos el método `SparkContext.textFile()`. También usaremos la función que acabamos de crear `removePunctuation()` dentro de una transformación `map()` para eliminar todos los caracteres no alfabéticos, numéricos o espacios. Dado que el archivo es bastante grande, usaremos `take(15)`, de forma que tan solo imprimiremos por pantalla las 15 primeras líneas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wOKwKY0LUAv4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in the beginning god created the heaven and the earth and the earth was without form and void and darkness was upon the face of the deep and the spirit of god moved upon the face of the waters',\n",
       " 'and god said let there be light and there was light',\n",
       " 'and god saw the light that it was good and god divided the light from the darkness',\n",
       " 'and god called the light day and the darkness he called night and the evening and the morning were the first day',\n",
       " 'and god said let there be a firmament in the midst of the waters and let it divide the waters from the waters',\n",
       " 'and god made the firmament and divided the waters which were under the firmament from the waters which were above the firmament and it was so',\n",
       " 'and god called the firmament heaven and the evening and the morning were the second day',\n",
       " 'and god said let the waters under the heaven be gathered together unto one place and let the dry land appear and it was so',\n",
       " 'and god called the dry land earth and the gathering together of the waters called he seas and god saw that it was good',\n",
       " 'and god said let the earth bring forth grass the herb yielding seed and the fruit tree yielding fruit after his kind whose seed is in itself upon the earth and it was so']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tan solo ejecuta este codigo\n",
    "import os.path\n",
    "\n",
    "fileName = os.path.join('/aula_B0.485/data', 'bible.txt')\n",
    "\n",
    "bibleRDD = sc.textFile(fileName, 8).map(removePunctuation).filter(lambda x: len(x)>0)\n",
    "bibleRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mib6R2D3UAv4"
   },
   "source": [
    "\n",
    "### (4d) Extraer las palabras de las líneas\n",
    "\n",
    "Antes de poder usar la función `wordcount()`, hemos de solucionar dos problemas con el formato del RDD:\n",
    "  + El primer problema es que necesitamos dividir cada línea por sus espacios. ** Esto lo solucionaremos en el apartado (4d). **\n",
    "  + El segundo problema es que necesitamos filtrar las líneas completamente vacías. ** Esto lo solucionaremos en el apartado (4e). **\n",
    "\n",
    "Para aplicar una transformación que divida cada elemento del RDD por sus espacios, hemos de aplicar la función incorporada en los strings de Python [split()](https://docs.python.org/2/library/string.html#string.split). Cuidado que a primera vista puede parecer que la función necesaria es una transformación `map()`, pero si piensas un poco más sobre el resultado de la función `split()` te darás cuenta que esta no es la opción correcta.\n",
    "\n",
    "> Nota:\n",
    "> * No uséis la implementación estándar del `split()`, debéis pasar un valor de separación. Por ejemplo, para dividir `line` por comas, usa `line.split(',')`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "h3xOMu-CUAv5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zuzims', 'zurishaddai', 'zurishaddai', 'zurishaddai', 'zurishaddai']\n",
      "766109\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "bibleWordsRDD = bibleRDD.flatMap(lambda line: line.split(' '))\n",
    "bibleWordsCount = bibleWordsRDD.count()\n",
    "print(bibleWordsRDD.top(5))\n",
    "print(bibleWordsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9pGO_0vXUAv5"
   },
   "outputs": [],
   "source": [
    "# TEST Words from lines (4d)\n",
    "# This test allows for leading spaces to be removed either before or after\n",
    "# punctuation is removed.\n",
    "assert bibleWordsCount == 766109, 'incorrect value for bibleWordsCount'\n",
    "assert bibleWordsRDD.top(5)==[u'zuzims', u'zurishaddai', u'zurishaddai', u'zurishaddai', u'zurishaddai'], 'incorrect value for bibleWordsRDD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_sje3BOUAv5"
   },
   "source": [
    "### (4e) Calcula palabras distintas\n",
    "\n",
    "El siguiente paso es contar cuantas palabras distintas contiene nuestro texto. Puedes usar las transformaciones map() y reduceByKey() ya utilizadas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "_r9BSj_TUAv5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'shiloh', 'tarsus', 'pharisees', 'tochen', 'avoided', 'babylonians', 'tents']\n",
      "12606\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "distintWordsMapRDD = bibleWordsRDD.map(lambda word: (word, 1))\n",
    "\n",
    "distintWordsRDD=distintWordsMapRDD.keys().distinct()\n",
    "\n",
    "print(distintWordsRDD.take(8))   \n",
    "print(distintWordsRDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "HrvMvo80UAv5"
   },
   "outputs": [],
   "source": [
    "# TEST Remove empty elements (4e)\n",
    "assert distintWordsRDD.count()== 12606, 'incorrect value for distintWordsRDD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZETOrsrLUAv5"
   },
   "source": [
    "### (4f) Cuenta las palabras\n",
    "\n",
    "Ahora que tenemos un RDD que contiene solo palabras. El siguiente paso es aplicar la función `wordCount()` para producir una lista con los conteos de palabras. Podemos ver las 15 más comunes usando la acción `takeOrdered()`; sin embargo, como los elementos del RRD son pares, necesitamos una función especial que ordene los pares de la forma correcta.\n",
    "\n",
    "Usad las funciones  `wordCount()` y `takeOrdered()` para obtener las 15 palabras más comunes junto con sus conteos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "LPECIEqwUAv5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 61680), ('and', 49862), ('of', 33195), ('to', 13031), ('that', 12561), ('in', 12211), ('he', 9939), ('shall', 9733), ('for', 8820), ('unto', 8808), ('i', 8712), ('his', 8141), ('a', 7997), ('lord', 7538), ('they', 7141)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "top15WordsAndCounts = wordCount(bibleWordsRDD).takeOrdered(15, key = lambda x: -x[1])\n",
    "print(top15WordsAndCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Q8lQntqLUAv5"
   },
   "outputs": [],
   "source": [
    "# TEST Count the words (4f)\n",
    "assert top15WordsAndCounts== [('the', 61680), ('and', 49862), \n",
    "                              ('of', 33195), ('to', 13031), \n",
    "                              ('that', 12561), ('in', 12211), \n",
    "                              ('he', 9939), ('shall', 9733), \n",
    "                              ('for', 8820), ('unto', 8808), \n",
    "                              ('i', 8712), ('his', 8141), ('a', 7997), \n",
    "                              ('lord', 7538), ('they', 7141)],'incorrect value for top15WordsAndCounts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlZfu470UAv5"
   },
   "source": [
    "## Parte 5: Calcular algunos estadísticos\n",
    "\n",
    "Usando las mismas técnicas que has aplicado en los ejercicios anteriores responde a las siguientes preguntas:\n",
    "\n",
    "\n",
    "### (5a) ¿Cuántas palabras distintas tienen exactamente 3 letras?\n",
    "(Mostrad por pantalla una muestra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "kKwMvhFeUAv5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of 3-letter words: ['out', 'raw', 'wax', 'hem', 'yet', 'bid', 'eri', 'are', 'jaw', 'lap']\n",
      "Total number of distinct 3-letter words: 301\n"
     ]
    }
   ],
   "source": [
    "threeLetterWordsRDD = bibleWordsRDD.filter(lambda word: len(word) == 3).distinct()\n",
    "\n",
    "threeLetterWordsCount = threeLetterWordsRDD.count()\n",
    "\n",
    "sampleThreeLetterWords = threeLetterWordsRDD.take(10)\n",
    "\n",
    "print(\"Sample of 3-letter words:\", sampleThreeLetterWords)\n",
    "print(\"Total number of distinct 3-letter words:\", threeLetterWordsCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAjhaRHxUAv5"
   },
   "source": [
    "### (5b) ¿Cuántas palabras distintas tienen en la tercera posición la vocal 'a'?\n",
    "(Mostrad por pantalla una muestra de las palabras ordenadas por longitud decreciente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "MErPqSuhUAv6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words with a in third position: 1249\n",
      "Sample of words sorted by descending length: ['maalehacrabbim', 'transgressions', 'grapegatherers', 'standardbearer', 'shamefacedness', 'grapegleanings', 'transgression', 'blasphemously', 'transgresseth', 'transgressest']\n"
     ]
    }
   ],
   "source": [
    "# Filtrar las palabras con 'a' en la tercera posición\n",
    "words_with_a_third_position = (\n",
    "    bibleWordsRDD\n",
    "    .filter(lambda word: len(word) >= 3 and word[2] == 'a')  # Filtrar palabras con 'a' en la tercera posición\n",
    "    .distinct()  # Eliminar duplicados\n",
    ")\n",
    "\n",
    "# Contar cuántas palabras cumplen la condición\n",
    "count = words_with_a_third_position.count()\n",
    "\n",
    "# Obtener una muestra de palabras ordenadas por longitud decreciente\n",
    "sample_sorted = (\n",
    "    words_with_a_third_position\n",
    "    .map(lambda word: (len(word), word))  # Crear pares (longitud, palabra)\n",
    "    .sortByKey(ascending=False)  # Ordenar por longitud (descendente)\n",
    "    .map(lambda x: x[1])  # Extraer solo las palabras\n",
    "    .take(10)  # Tomar las primeras 10 palabras\n",
    ")\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Total words with a in third position: {}\".format(count))\n",
    "print(\"Sample of words sorted by descending length: {}\".format(sample_sorted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9brp6E-gUAv6"
   },
   "source": [
    "### (5c) ¿Cuáles son las 10 palabras más largas? De éstas, ¿cuántas tienen 3 o más vocales?\n",
    "Mostradlas por pantalla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "UeSLrBjpUAv6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 longest words:\n",
      "['mahershalalhashbaz', 'chushanrishathaim', 'unprofitableness', 'lovingkindnesses', 'covenantbreakers', 'selahammahlekoth', 'bashanhavothjair', 'kibrothhattaavah', 'chepharhaammonai', 'evilfavouredness']\n",
      "\n",
      "Words with 3 or more vowels:\n",
      "['remaining', 'eliada', 'jahdai', 'babylonians', 'createth', 'winebibber', 'benefactors', 'attired', 'desirable', 'costliness']\n"
     ]
    }
   ],
   "source": [
    "# 1. Obtener las 10 palabras más largas\n",
    "top10LongestWords = bibleWordsRDD.map(lambda word: (word, len(word))) \\\n",
    "                                .distinct() \\\n",
    "                                .takeOrdered(10, key=lambda x: -x[1])\n",
    "\n",
    "# 2. Filtrar palabras con 3 o más vocales\n",
    "def count_vowels(word):\n",
    "    vowels = 'aeiou'\n",
    "    return sum(1 for char in word if char in vowels)\n",
    "\n",
    "wordsWithThreeOrMoreVowels = bibleWordsRDD.filter(lambda word: count_vowels(word) >= 3).distinct()\n",
    "\n",
    "# 3. Imprimir los resultados\n",
    "print(\"Top 10 longest words:\")\n",
    "print([word for word, length in top10LongestWords])\n",
    "\n",
    "\n",
    "# Mostramos las primeras 10 palabras con 3 o más vocales\n",
    "print(\"\\nWords with 3 or more vowels:\")\n",
    "print(wordsWithThreeOrMoreVowels.take(10))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "nygi0_YgUAv1",
    "-ao3HOCnUAv2",
    "9R6uGj_XUAv2",
    "bul8z1FxUAv3",
    "3zLHxu4VUAv3",
    "tPyU-FY2UAv4",
    "s2uFF4D7UAv4",
    "Mib6R2D3UAv4",
    "X_sje3BOUAv5",
    "ZETOrsrLUAv5",
    "gAjhaRHxUAv5",
    "9brp6E-gUAv6"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "Lab_1_WordCount",
  "notebookId": 1529163670453288
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
